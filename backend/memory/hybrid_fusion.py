"""
Hybrid Fusion Layer for RAG v2.0

Combines lexical (BM25) and semantic (vector) retrieval with:
- Adaptive weighting (query-aware)
- Reciprocal Rank Fusion
- Smart query analysis (decides when to use BM25)
- Metadata-aware boosting

Expected gain: +5-10% relevance improvement
"""
import numpy as np
import re
from typing import List, Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class HybridFusion:
    """
    Advanced hybrid retrieval fusion with adaptive weighting.
    
    Implements multiple fusion strategies:
    1. Weighted score fusion (configurable alpha)
    2. Adaptive alpha based on query characteristics
    3. Smart query analysis (use BM25 only when beneficial)
    4. Reciprocal Rank Fusion (RRF)
    5. Metadata-aware boosting
    """
    
    def __init__(
        self,
        default_alpha: float = 0.75,  # Weight for vector score
        enable_adaptive: bool = True,
        enable_rrf: bool = False,
        rrf_k: int = 60
    ):
        """
        Initialize hybrid fusion layer.
        
        Args:
            default_alpha: Default weight for vector score (0-1)
            enable_adaptive: Use query-aware alpha adaptation
            enable_rrf: Use Reciprocal Rank Fusion instead of score fusion
            rrf_k: RRF constant (default: 60)
        """
        self.default_alpha = default_alpha
        self.enable_adaptive = enable_adaptive
        self.enable_rrf = enable_rrf
        self.rrf_k = rrf_k
        
        logger.info(f"HybridFusion initialized: alpha={default_alpha}, adaptive={enable_adaptive}, rrf={enable_rrf}")
    
    def normalize_scores(
        self,
        candidates: List[Dict[str, Any]],
        vector_key: str = 'vector_score',
        lexical_key: str = 'lexical_score'
    ) -> List[Dict[str, Any]]:
        """
        Normalize scores using DIRECT PASS-THROUGH with optional scaling.
        
        CRITICAL FIX: Min-max normalization on small batches destroys discrimination
        because the top candidate always becomes 1.0 and bottom becomes 0.0.
        
        Instead, we PRESERVE the original score distributions since:
        - Vector scores (cosine similarity) are already in [0, 1]
        - Lexical scores (BM25 normalized) are already in [0, 1]
        
        This maintains the natural score distributions and prevents artificial
        score convergence.
        
        Args:
            candidates: List of candidate results
            vector_key: Key for vector score in candidate dict
            lexical_key: Key for lexical/BM25 score in candidate dict
            
        Returns:
            Candidates with normalized scores added
        """
        if not candidates:
            return candidates
        
        # DIRECT PASS-THROUGH: Use original scores
        for candidate in candidates:
            # Vector scores (cosine similarity) are already [0, 1]
            candidate['vector_norm'] = candidate.get(vector_key, 0.0)
            
            # Lexical scores (BM25 normalized) are already [0, 1]
            candidate['lexical_norm'] = candidate.get(lexical_key, 0.0)
        
        return candidates
    
    
    def should_use_lexical(self, query: str) -> bool:
        """
        Determine if BM25 lexical retrieval should be used for this query.
        
        BM25 works best with:
        - Specific keywords (proper nouns, technical terms, numbers)
        - Exact phrase matching
        - Queries with unique/rare terms
        
        BM25 performs poorly with:
        - Conceptual/semantic queries ("what is", "explain")
        - Short queries with common words
        - Paraphrased or synonym-rich queries
        
        CONSERVATIVE STRATEGY: Default to vector-only unless strong signals
        that lexical will help (proper nouns, numbers, technical terms).
        
        Args:
            query: Search query string
            
        Returns:
            True if lexical fusion recommended, False for vector-only
        """
        query_lower = query.lower()
        
        # SIMPLIFIED: Only go vector-only for VERY semantic queries
        # Be conservative - default to hybrid to preserve BM25 signal
        semantic_patterns = [
            r'\bwhat\s+(is|are)\b',          # "what is X" - definitional
            r'\bexplain\s+(the|how|why)\b',  # "explain X" - conceptual
            r'\bdescribe\s+',                 # "describe X" - descriptive
        ]
        
        for pattern in semantic_patterns:
            if re.search(pattern, query_lower):
                logger.debug(f"Strong semantic pattern matched: '{query}' - using vector-only")
                return False
        
        # DEFAULT: Use hybrid mode (combines vector + BM25)
        logger.debug(f"No strong semantic signal - using hybrid mode")
        return True
    
    def compute_adaptive_alpha(self, query: str) -> float:
        """
        Compute query-aware alpha weight.
        
        Strategy (TUNED - less extreme than before):
        - Short queries (<5 words): alpha=0.70 â†’ 70% semantic, 30% lexical
        - Medium queries (5-15 words): alpha=0.60 â†’ balanced
        - Long queries (>15 words): alpha=0.50 â†’ equal weight
        
        Rationale: BM25 can help even on semantic queries by matching
        important keywords. Previous 0.90/0.85/0.80 was too vector-heavy.
        
        Args:
            query: Search query string
            
        Returns:
            Alpha weight (0-1)
        """
        if not self.enable_adaptive:
            return self.default_alpha
        
        query_length = len(query.split())
        
        if query_length < 5:
            return 0.70  # Short query â†’ 70% semantic, 30% lexical
        elif query_length > 15:
            return 0.50  # Long query â†’ balanced 50/50
        else:
            return 0.60  # Medium query â†’ 60% semantic, 40% lexical
    
    def weighted_fusion(
        self,
        candidates: List[Dict[str, Any]],
        query: str,
        alpha: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        """
        Compute hybrid scores using weighted fusion.
        
        Formula: hybrid_score = alpha * vector_norm + (1 - alpha) * lexical_norm
        
        Args:
            candidates: Normalized candidates
            query: Search query for adaptive alpha
            alpha: Override alpha (if None, uses adaptive)
            
        Returns:
            Candidates with hybrid_score added
        """
        if alpha is None:
            alpha = self.compute_adaptive_alpha(query)
        
        for candidate in candidates:
            v_score = candidate.get('vector_norm', 0.0)
            l_score = candidate.get('lexical_norm', 0.0)
            
            candidate['hybrid_score'] = alpha * v_score + (1 - alpha) * l_score
            candidate['alpha_used'] = alpha
        
        logger.debug(f"Weighted fusion: alpha={alpha:.2f}, n_candidates={len(candidates)}")
        return candidates
    
    def reciprocal_rank_fusion(
        self,
        vector_ranks: List[int],
        lexical_ranks: List[int],
        weight: float = 0.5
    ) -> List[float]:
        """
        Compute Reciprocal Rank Fusion (RRF) scores.
        
        Formula: RRF = Î£ weight / (rank + k)
        
        Args:
            vector_ranks: Ranks from vector retrieval (0-indexed)
            lexical_ranks: Ranks from lexical retrieval (0-indexed)
            weight: Relative weight (0-1)
            
        Returns:
            List of RRF scores
        """
        scores = []
        for v_rank, l_rank in zip(vector_ranks, lexical_ranks):
            v_contrib = weight / (v_rank + self.rrf_k)
            l_contrib = (1 - weight) / (l_rank + self.rrf_k)
            scores.append(v_contrib + l_contrib)
        
        return scores
    
    def apply_metadata_boost(
        self,
        candidates: List[Dict[str, Any]],
        authority_weight: float = 0.6,
        recency_weight: float = 0.4,
        boost_strength: float = 0.2
    ) -> List[Dict[str, Any]]:
        """
        Apply metadata-based boosting to hybrid scores.
        
        Formula: final_score = (1 - boost_strength) * hybrid_score + boost_strength * metadata_boost
        
        Args:
            candidates: Candidates with hybrid_score
            authority_weight: Weight for authority score (0-1)
            recency_weight: Weight for recency score (0-1)
            boost_strength: Overall boost influence (0-1)
            
        Returns:
            Candidates with final_score added
        """
        for candidate in candidates:
            metadata = candidate.get('metadata', {})
            
            # Extract metadata scores (0-1)
            authority = metadata.get('authority_score', 0.5)
            recency = metadata.get('recency_score', 0.5)
            
            # Compute metadata boost
            metadata_boost = authority_weight * authority + recency_weight * recency
            
            # Apply to hybrid score
            hybrid_score = candidate.get('hybrid_score', 0.0)
            candidate['metadata_boost'] = metadata_boost
            candidate['final_score'] = (
                (1 - boost_strength) * hybrid_score + 
                boost_strength * metadata_boost
            )
        
        return candidates
    
    def adaptive_threshold(
        self,
        candidates: List[Dict[str, Any]],
        percentile: float = 15.0,
        score_key: str = 'final_score'
    ) -> List[Dict[str, Any]]:
        """
        Filter candidates using adaptive percentile threshold.
        
        Args:
            candidates: Candidates with scores
            percentile: Percentile threshold (0-100)
            score_key: Score key to threshold on
            
        Returns:
            Filtered candidates above threshold
        """
        if not candidates:
            return candidates
        
        scores = [c.get(score_key, 0.0) for c in candidates]
        threshold = np.percentile(scores, percentile)
        
        filtered = [c for c in candidates if c.get(score_key, 0.0) >= threshold]
        
        logger.debug(f"Adaptive threshold: percentile={percentile}, threshold={threshold:.3f}, kept={len(filtered)}/{len(candidates)}")
        
        return filtered
    
    def fuse(
        self,
        candidates: List[Dict[str, Any]],
        query: str,
        apply_metadata: bool = True,
        apply_threshold: bool = True,
        force_lexical: bool = False  # Override smart analysis
    ) -> List[Dict[str, Any]]:
        """
        Complete hybrid fusion pipeline with smart query analysis.
        
        Steps:
        0. Smart query analysis (decide if BM25 helps or hurts)
        1. If semantic query â†’ use vector-only (skip BM25)
        2. If keyword query â†’ normalize scores
        3. Compute hybrid scores (weighted or RRF)
        4. Apply metadata boost
        5. Apply adaptive threshold
        6. Sort by final score
        
        Args:
            candidates: Raw candidates from retrievers
            query: Search query
            apply_metadata: Whether to apply metadata boosting
            apply_threshold: Whether to apply adaptive thresholding
            force_lexical: Override smart analysis and always use lexical
            
        Returns:
            Fused and ranked candidates
        """
        if not candidates:
            return candidates
        
        # Step 0: Smart query analysis
        use_lexical = force_lexical or self.should_use_lexical(query)
        
        if not use_lexical:
            # Semantic query â†’ vector-only (ignore BM25 scores)
            logger.info(f"ðŸ“Š VECTOR-ONLY MODE: Semantic query detected, skipping lexical fusion")
            
            # Filter out lexical-only results (vector_score=0)
            vector_candidates = [c for c in candidates if c.get('vector_score', 0.0) > 0]
            logger.info(f"ðŸ” VECTOR-ONLY: Filtered {len(candidates)} â†’ {len(vector_candidates)} (removed lexical-only results)")
            
            for candidate in vector_candidates:
                # Use vector score as base
                vector_score = candidate.get('vector_score', 0.0)
                candidate['vector_norm'] = vector_score
                candidate['lexical_norm'] = 0.0  # Ignore lexical
                candidate['hybrid_score'] = vector_score  # 100% vector
                candidate['final_score'] = vector_score  # NO BOOST - use raw score for testing
                candidate['alpha_used'] = 1.0  # 100% semantic
            
            # Sort by final score
            vector_candidates.sort(key=lambda x: x.get('final_score', 0.0), reverse=True)
            logger.info(f"âœ… VECTOR-ONLY: Returning {len(vector_candidates)} results (NO metadata boost)")
            return vector_candidates
        else:
            # Keyword query â†’ use hybrid fusion
            logger.info(f"ðŸ“Š HYBRID MODE: Keyword query detected, using lexical fusion")
            
            # Step 1: Normalize
            candidates = self.normalize_scores(candidates)
            
            # Step 2: Hybrid fusion
            if self.enable_rrf:
                # TODO: Implement RRF (requires rank information)
                logger.warning("RRF not yet implemented, falling back to weighted fusion")
                candidates = self.weighted_fusion(candidates, query)
            else:
                candidates = self.weighted_fusion(candidates, query)
        
        # Step 3: Metadata boost (DISABLED - hurting performance)
        if False:  # apply_metadata:
            candidates = self.apply_metadata_boost(
                candidates,
                authority_weight=0.7,
                recency_weight=0.3,
                boost_strength=0.15
            )
            score_key = 'final_score'
        else:
            # Use hybrid_score without metadata boost
            for c in candidates:
                c['final_score'] = c.get('hybrid_score', 0.0)
            score_key = 'hybrid_score'
        
        # Step 4: Adaptive threshold
        if apply_threshold:
            candidates = self.adaptive_threshold(candidates, score_key=score_key)
        
        # Step 5: Sort by final score
        candidates.sort(key=lambda x: x.get(score_key, 0.0), reverse=True)
        
        return candidates


# Global singleton
_hybrid_fusion: Optional[HybridFusion] = None


def get_hybrid_fusion(reset: bool = False, **kwargs) -> HybridFusion:
    """
    Get or create global HybridFusion instance.
    
    Args:
        reset: Whether to reset the singleton
        **kwargs: Arguments for HybridFusion constructor
        
    Returns:
        HybridFusion instance
    """
    global _hybrid_fusion
    
    if reset or _hybrid_fusion is None:
        _hybrid_fusion = HybridFusion(**kwargs)
    
    return _hybrid_fusion
